{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12cxlPCf64dxZR8NiRfZd4vb9vl1diA4E",
      "authorship_tag": "ABX9TyODWRXYf7mtvGdJ9e+6A6ko",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YakshRathod/NULLCLASS-Internship/blob/Task-5/Task_5_Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAldHNp8IbwC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_dir = \"/content/drive/MyDrive/Nullclass internship/Task 1/Shapes Dataset\"\n",
        "img_files = [f for f in os.listdir(img_dir) if f.lower().endswith('.png')]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "embeddings = []\n",
        "labels = []\n",
        "\n",
        "for fname in img_files:\n",
        "    try:\n",
        "        shape, color, idx = fname[:-4].split('_')\n",
        "        text = shape                      # <-- Only use shape!\n",
        "        labels.append(text)\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            emb = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
        "            embeddings.append(emb)\n",
        "    except Exception as e:\n",
        "        print(\"Error with file:\", fname, e)\n",
        "\n",
        "embeddings = np.array(embeddings)\n",
        "print(\"Embeddings shape:\", embeddings.shape)  # [num_images, 768]\n",
        "\n",
        "np.save('/content/drive/MyDrive/Nullclass internship/Task 5/shape_label_embeddings.npy', embeddings)\n",
        "print(\"Saved embeddings to shape_label_embeddings.npy\")\n",
        "with open('/content/drive/MyDrive/Nullclass internship/Task 5/shape_labels.txt', 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write(label + \"\\n\")\n",
        "\n",
        "# --- PCA of unique shape embeddings only ---\n",
        "unique_shapes = sorted(set(labels))\n",
        "unique_embeddings = []\n",
        "for shape in unique_shapes:\n",
        "    idx = labels.index(shape)            # pick the first occurrence for each shape\n",
        "    unique_embeddings.append(embeddings[idx])\n",
        "unique_embeddings = np.array(unique_embeddings)\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "proj = pca.fit_transform(unique_embeddings)\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.scatter(proj[:, 0], proj[:, 1], color='royalblue')\n",
        "for i, shape in enumerate(unique_shapes):\n",
        "    plt.annotate(shape, (proj[i, 0], proj[i, 1]), fontsize=12)\n",
        "plt.title(\"PCA of Unique Shape Label Embeddings\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}